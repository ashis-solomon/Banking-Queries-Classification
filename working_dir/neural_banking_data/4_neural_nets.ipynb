{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "509c04a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 12:30:03.649680: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-03-26 12:30:03.834044: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-03-26 12:30:03.836136: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-26 12:30:04.586480: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-03-26 12:30:10.780664: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-03-26 12:30:10.992149: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-26 12:30:10.993216: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-26 12:30:10.994420: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 12:30:11.104295: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-03-26 12:30:11.143221: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-26 12:30:11.144335: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-26 12:30:11.145329: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-03-26 12:30:11.465090: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-26 12:30:11.466308: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-26 12:30:11.467245: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-03-26 12:30:11.590145: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-03-26 12:30:11.635946: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-26 12:30:11.638233: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-26 12:30:11.641002: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-03-26 12:30:12.026247: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-03-26 12:30:12.364493: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-26 12:30:12.365880: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-26 12:30:12.366859: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-03-26 12:30:12.473529: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-03-26 12:30:12.511130: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-26 12:30:12.512387: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-26 12:30:12.513374: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-03-26 12:30:12.879197: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479/479 [==============================] - ETA: 0s - loss: 0.5208 - accuracy: 0.8096"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 12:30:49.842108: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-26 12:30:49.843227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-26 12:30:49.844450: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-03-26 12:30:49.944063: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-03-26 12:30:49.979957: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-26 12:30:49.981159: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-26 12:30:49.982163: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479/479 [==============================] - 40s 78ms/step - loss: 0.5208 - accuracy: 0.8096 - val_loss: 0.3841 - val_accuracy: 0.8643\n",
      "Epoch 2/10\n",
      "479/479 [==============================] - 36s 75ms/step - loss: 0.2436 - accuracy: 0.9137 - val_loss: 0.3433 - val_accuracy: 0.8793\n",
      "Epoch 3/10\n",
      "479/479 [==============================] - 36s 76ms/step - loss: 0.1902 - accuracy: 0.9353 - val_loss: 0.3473 - val_accuracy: 0.8877\n",
      "Epoch 4/10\n",
      "479/479 [==============================] - 37s 78ms/step - loss: 0.1563 - accuracy: 0.9449 - val_loss: 0.3648 - val_accuracy: 0.8850\n",
      "Epoch 5/10\n",
      "479/479 [==============================] - 37s 78ms/step - loss: 0.1378 - accuracy: 0.9536 - val_loss: 0.3734 - val_accuracy: 0.8884\n",
      "Epoch 6/10\n",
      "479/479 [==============================] - 38s 78ms/step - loss: 0.1271 - accuracy: 0.9589 - val_loss: 0.3625 - val_accuracy: 0.8938\n",
      "Epoch 7/10\n",
      "479/479 [==============================] - 38s 79ms/step - loss: 0.1076 - accuracy: 0.9647 - val_loss: 0.3791 - val_accuracy: 0.8922\n",
      "Epoch 8/10\n",
      "479/479 [==============================] - 38s 79ms/step - loss: 0.0966 - accuracy: 0.9683 - val_loss: 0.4055 - val_accuracy: 0.8915\n",
      "Epoch 9/10\n",
      "479/479 [==============================] - 38s 79ms/step - loss: 0.0838 - accuracy: 0.9722 - val_loss: 0.4330 - val_accuracy: 0.8892\n",
      "Epoch 10/10\n",
      "479/479 [==============================] - 38s 79ms/step - loss: 0.0752 - accuracy: 0.9745 - val_loss: 0.4534 - val_accuracy: 0.8911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 12:36:27.426154: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-26 12:36:27.427301: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-26 12:36:27.428272: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-03-26 12:36:27.527430: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-03-26 12:36:27.562157: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-26 12:36:27.563230: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-26 12:36:27.564497: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 1s 12ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       501\n",
      "           1       0.89      0.88      0.88       823\n",
      "           2       0.87      0.87      0.87       974\n",
      "           3       0.93      0.93      0.93       319\n",
      "\n",
      "    accuracy                           0.88      2617\n",
      "   macro avg       0.88      0.89      0.89      2617\n",
      "weighted avg       0.88      0.88      0.88      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('final_project_cleaned.csv')\n",
    "\n",
    "# Preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # Join tokens back into text\n",
    "    text = ' '.join(tokens)\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the text data and pad the sequences to a fixed length\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_seq_padded = pad_sequences(X_train_seq, maxlen=100)\n",
    "\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_seq_padded = pad_sequences(X_test_seq, maxlen=100)\n",
    "\n",
    "# Use RandomOversampling to oversample the minority classes in the training data\n",
    "ros = RandomOverSampler()\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_seq_padded, y_train)\n",
    "def create_bilstm(num_words=20000, lstm_size=64, embedding_size=128, dropout_rate=0.3, dense_size=64):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(num_words, embedding_size, input_length=100))\n",
    "    model.add(Bidirectional(LSTM(lstm_size)))\n",
    "    model.add(Dense(dense_size, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define a callback to save the model with the best validation accuracy\n",
    "best_model = ModelCheckpoint('best_model.h5', save_best_only=True, save_weights_only=False, monitor='val_accuracy', mode='max')\n",
    "bilstm_model = create_bilstm()\n",
    "y_train_resampled = pd.Categorical(y_train_resampled)\n",
    "y_train_resampled = y_train_resampled.codes\n",
    "y_train_resampled_cat = pd.get_dummies(y_train_resampled).values\n",
    "y_test = pd.Categorical(y_test)\n",
    "y_test = y_test.codes\n",
    "y_test_cat = pd.get_dummies(y_test).values\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "filepath='best_model.h5',\n",
    "monitor='val_loss',\n",
    "save_best_only=True,\n",
    "save_weights_only=False,\n",
    "mode='auto',\n",
    "save_freq='epoch'\n",
    ")\n",
    "\n",
    "bilstm_history = bilstm_model.fit(X_train_resampled, y_train_resampled_cat,\n",
    "epochs=10,\n",
    "batch_size=32,\n",
    "validation_data=(X_test_seq_padded, y_test_cat),\n",
    "callbacks=[checkpoint_callback])\n",
    "\n",
    "#Load the best model\n",
    "bilstm_model.load_weights('best_model.h5')\n",
    "\n",
    "#Evaluate the model on the test set\n",
    "y_pred = bilstm_model.predict(X_test_seq_padded)\n",
    "y_pred_class = y_pred.argmax(axis=-1)\n",
    "print(classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d8f975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 12:40:35.621870: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-26 12:40:35.623158: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-26 12:40:35.624119: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-03-26 12:40:35.821543: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-26 12:40:35.822699: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-26 12:40:35.824073: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-03-26 12:40:36.450934: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-26 12:40:36.452135: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-26 12:40:36.453150: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479/479 [==============================] - ETA: 0s - loss: 0.5388 - accuracy: 0.8014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 12:41:08.371525: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-26 12:41:08.373272: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-26 12:41:08.374234: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479/479 [==============================] - 34s 67ms/step - loss: 0.5388 - accuracy: 0.8014 - val_loss: 0.3756 - val_accuracy: 0.8636\n",
      "Epoch 2/10\n",
      "479/479 [==============================] - 32s 67ms/step - loss: 0.2467 - accuracy: 0.9130 - val_loss: 0.3693 - val_accuracy: 0.8682\n",
      "Epoch 3/10\n",
      "479/479 [==============================] - 32s 67ms/step - loss: 0.1931 - accuracy: 0.9343 - val_loss: 0.3698 - val_accuracy: 0.8708\n",
      "Epoch 4/10\n",
      "479/479 [==============================] - 32s 66ms/step - loss: 0.1620 - accuracy: 0.9448 - val_loss: 0.3529 - val_accuracy: 0.8804\n",
      "Epoch 5/10\n",
      "479/479 [==============================] - 32s 67ms/step - loss: 0.1418 - accuracy: 0.9523 - val_loss: 0.3743 - val_accuracy: 0.8846\n",
      "Epoch 6/10\n",
      "479/479 [==============================] - 32s 67ms/step - loss: 0.1241 - accuracy: 0.9585 - val_loss: 0.3921 - val_accuracy: 0.8892\n",
      "Epoch 7/10\n",
      "479/479 [==============================] - 32s 67ms/step - loss: 0.1086 - accuracy: 0.9653 - val_loss: 0.3737 - val_accuracy: 0.8877\n",
      "Epoch 8/10\n",
      "479/479 [==============================] - 32s 67ms/step - loss: 0.0952 - accuracy: 0.9673 - val_loss: 0.4143 - val_accuracy: 0.8907\n",
      "Epoch 9/10\n",
      "479/479 [==============================] - 32s 67ms/step - loss: 0.0880 - accuracy: 0.9705 - val_loss: 0.4207 - val_accuracy: 0.8838\n",
      "Epoch 10/10\n",
      "479/479 [==============================] - 32s 67ms/step - loss: 0.0798 - accuracy: 0.9737 - val_loss: 0.3901 - val_accuracy: 0.8972\n",
      " 6/82 [=>............................] - ETA: 0s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 12:45:57.217519: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-26 12:45:57.218648: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-26 12:45:57.219672: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 1s 11ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       501\n",
      "           1       0.89      0.88      0.88       823\n",
      "           2       0.88      0.86      0.87       974\n",
      "           3       0.92      0.92      0.92       319\n",
      "\n",
      "    accuracy                           0.88      2617\n",
      "   macro avg       0.88      0.89      0.89      2617\n",
      "weighted avg       0.88      0.88      0.88      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('final_project_cleaned.csv')\n",
    "\n",
    "# Preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # Join tokens back into text\n",
    "    text = ' '.join(tokens)\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the text data and pad the sequences to a fixed length\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_seq_padded = pad_sequences(X_train_seq, maxlen=100)\n",
    "\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_seq_padded = pad_sequences(X_test_seq, maxlen=100)\n",
    "\n",
    "# Use RandomOversampling to oversample the minority classes in the training data\n",
    "ros = RandomOverSampler()\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_seq_padded, y_train)\n",
    "def create_lstm(num_words=20000, lstm_size=64, embedding_size=128, dropout_rate=0.3, dense_size=64):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(num_words, embedding_size, input_length=100))\n",
    "    model.add(LSTM(lstm_size))\n",
    "    model.add(Dense(dense_size, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define a callback to save the model with the best validation accuracy\n",
    "best_model = ModelCheckpoint('best_model.h5', save_best_only=True, save_weights_only=False, monitor='val_accuracy', mode='max')\n",
    "lstm_model = create_lstm()\n",
    "y_train_resampled = pd.Categorical(y_train_resampled)\n",
    "y_train_resampled = y_train_resampled.codes\n",
    "y_train_resampled_cat = pd.get_dummies(y_train_resampled).values\n",
    "y_test = pd.Categorical(y_test)\n",
    "y_test = y_test.codes\n",
    "y_test_cat = pd.get_dummies(y_test).values\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "filepath='best_model.h5',\n",
    "monitor='val_loss',\n",
    "save_best_only=True,\n",
    "save_weights_only=False,\n",
    "mode='auto',\n",
    "save_freq='epoch'\n",
    ")\n",
    "\n",
    "lstm_history = lstm_model.fit(X_train_resampled, y_train_resampled_cat,\n",
    "epochs=10,\n",
    "batch_size=32,\n",
    "validation_data=(X_test_seq_padded, y_test_cat),\n",
    "callbacks=[checkpoint_callback])\n",
    "\n",
    "#Load the best model\n",
    "lstm_model.load_weights('best_model.h5')\n",
    "\n",
    "#Evaluate the model on the test set\n",
    "y_pred = lstm_model.predict(X_test_seq_padded)\n",
    "y_pred_class = y_pred.argmax(axis=-1)\n",
    "print(classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a582b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 13:27:59.807078: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-03-26 13:27:59.844214: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-03-26 13:27:59.845087: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-26 13:28:00.422010: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 13:28:06.077501: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479/479 [==============================] - 22s 46ms/step - loss: 0.5726 - accuracy: 0.7808 - val_loss: 0.3636 - val_accuracy: 0.8643\n",
      "Epoch 2/10\n",
      "479/479 [==============================] - 22s 46ms/step - loss: 0.2090 - accuracy: 0.9264 - val_loss: 0.3236 - val_accuracy: 0.8907\n",
      "Epoch 3/10\n",
      "479/479 [==============================] - 22s 46ms/step - loss: 0.1324 - accuracy: 0.9542 - val_loss: 0.3490 - val_accuracy: 0.8877\n",
      "Epoch 4/10\n",
      "479/479 [==============================] - 21s 43ms/step - loss: 0.0959 - accuracy: 0.9689 - val_loss: 0.3577 - val_accuracy: 0.8884\n",
      "Epoch 5/10\n",
      "479/479 [==============================] - 22s 47ms/step - loss: 0.0689 - accuracy: 0.9779 - val_loss: 0.3678 - val_accuracy: 0.8919\n",
      "Epoch 6/10\n",
      "479/479 [==============================] - 20s 42ms/step - loss: 0.0523 - accuracy: 0.9832 - val_loss: 0.4104 - val_accuracy: 0.8945\n",
      "Epoch 7/10\n",
      "479/479 [==============================] - 20s 42ms/step - loss: 0.0461 - accuracy: 0.9859 - val_loss: 0.4369 - val_accuracy: 0.8980\n",
      "Epoch 8/10\n",
      "479/479 [==============================] - 20s 42ms/step - loss: 0.0388 - accuracy: 0.9890 - val_loss: 0.4511 - val_accuracy: 0.8930\n",
      "Epoch 9/10\n",
      "479/479 [==============================] - 20s 42ms/step - loss: 0.0340 - accuracy: 0.9894 - val_loss: 0.4831 - val_accuracy: 0.8865\n",
      "Epoch 10/10\n",
      "479/479 [==============================] - 22s 45ms/step - loss: 0.0309 - accuracy: 0.9910 - val_loss: 0.6217 - val_accuracy: 0.8686\n",
      "82/82 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88       501\n",
      "           1       0.87      0.90      0.88       823\n",
      "           2       0.89      0.88      0.89       974\n",
      "           3       0.95      0.93      0.94       319\n",
      "\n",
      "    accuracy                           0.89      2617\n",
      "   macro avg       0.90      0.89      0.90      2617\n",
      "weighted avg       0.89      0.89      0.89      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('final_project_cleaned.csv')\n",
    "\n",
    "# Preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # Join tokens back into text\n",
    "    text = ' '.join(tokens)\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the text data and pad the sequences to a fixed length\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_seq_padded = pad_sequences(X_train_seq, maxlen=100)\n",
    "\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_seq_padded = pad_sequences(X_test_seq, maxlen=100)\n",
    "\n",
    "# Use RandomOversampling to oversample the minority classes in the training data\n",
    "ros = RandomOverSampler()\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_seq_padded, y_train)\n",
    "def create_cnn(num_words=20000, embedding_size=128, filter_size=32, kernel_size=3, pool_size=2, dense_size=64, dropout_rate=0.3):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(num_words, embedding_size, input_length=100))\n",
    "    model.add(Conv1D(filters=filter_size, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    model.add(Conv1D(filters=filter_size, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(dense_size, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define a callback to save the model with the best validation accuracy\n",
    "best_model = ModelCheckpoint('best_model.h5', save_best_only=True, save_weights_only=False, monitor='val_accuracy', mode='max')\n",
    "cnn_model = create_cnn()\n",
    "y_train_resampled = pd.Categorical(y_train_resampled)\n",
    "y_train_resampled = y_train_resampled.codes\n",
    "y_train_resampled_cat = pd.get_dummies(y_train_resampled).values\n",
    "y_test = pd.Categorical(y_test)\n",
    "y_test = y_test.codes\n",
    "y_test_cat = pd.get_dummies(y_test).values\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "filepath='best_model.h5',\n",
    "monitor='val_loss',\n",
    "save_best_only=True,\n",
    "save_weights_only=False,\n",
    "mode='auto',\n",
    "save_freq='epoch'\n",
    ")\n",
    "\n",
    "cnn_history = cnn_model.fit(X_train_resampled, y_train_resampled_cat,\n",
    "epochs=10,\n",
    "batch_size=32,\n",
    "validation_data=(X_test_seq_padded, y_test_cat),\n",
    "callbacks=[checkpoint_callback])\n",
    "\n",
    "#Load the best model\n",
    "cnn_model.load_weights('best_model.h5')\n",
    "\n",
    "#Evaluate the model on the test set\n",
    "y_pred = cnn_model.predict(X_test_seq_padded)\n",
    "y_pred_class = y_pred.argmax(axis=-1)\n",
    "print(classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47f12f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "479/479 [==============================] - 19s 38ms/step - loss: 0.6065 - accuracy: 0.7616 - val_loss: 0.4268 - val_accuracy: 0.8441\n",
      "Epoch 2/10\n",
      "479/479 [==============================] - 18s 38ms/step - loss: 0.2447 - accuracy: 0.9146 - val_loss: 0.3838 - val_accuracy: 0.8617\n",
      "Epoch 3/10\n",
      "479/479 [==============================] - 18s 38ms/step - loss: 0.1776 - accuracy: 0.9366 - val_loss: 0.4071 - val_accuracy: 0.8647\n",
      "Epoch 4/10\n",
      "479/479 [==============================] - 18s 38ms/step - loss: 0.1379 - accuracy: 0.9523 - val_loss: 0.4380 - val_accuracy: 0.8544\n",
      "Epoch 5/10\n",
      "479/479 [==============================] - 18s 38ms/step - loss: 0.1127 - accuracy: 0.9613 - val_loss: 0.4717 - val_accuracy: 0.8582\n",
      "Epoch 6/10\n",
      "479/479 [==============================] - 18s 38ms/step - loss: 0.1054 - accuracy: 0.9638 - val_loss: 0.8283 - val_accuracy: 0.7390\n",
      "Epoch 7/10\n",
      "479/479 [==============================] - 18s 38ms/step - loss: 0.1584 - accuracy: 0.9447 - val_loss: 0.5090 - val_accuracy: 0.8521\n",
      "Epoch 8/10\n",
      "479/479 [==============================] - 18s 38ms/step - loss: 0.0810 - accuracy: 0.9718 - val_loss: 0.5319 - val_accuracy: 0.8563\n",
      "Epoch 9/10\n",
      "479/479 [==============================] - 18s 38ms/step - loss: 0.0659 - accuracy: 0.9780 - val_loss: 0.5494 - val_accuracy: 0.8598\n",
      "Epoch 10/10\n",
      "479/479 [==============================] - 18s 38ms/step - loss: 0.0669 - accuracy: 0.9779 - val_loss: 0.6008 - val_accuracy: 0.8544\n",
      "82/82 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       501\n",
      "           1       0.83      0.89      0.86       823\n",
      "           2       0.88      0.82      0.85       974\n",
      "           3       0.94      0.90      0.92       319\n",
      "\n",
      "    accuracy                           0.86      2617\n",
      "   macro avg       0.87      0.87      0.87      2617\n",
      "weighted avg       0.86      0.86      0.86      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('final_project_cleaned.csv')\n",
    "\n",
    "# Preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # Join tokens back into text\n",
    "    text = ' '.join(tokens)\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the text data and pad the sequences to a fixed length\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_seq_padded = pad_sequences(X_train_seq, maxlen=100)\n",
    "\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_seq_padded = pad_sequences(X_test_seq, maxlen=100)\n",
    "\n",
    "# Use RandomOversampling to oversample the minority classes in the training data\n",
    "ros = RandomOverSampler()\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_seq_padded, y_train)\n",
    "def create_rnn(num_words=20000, embedding_dim=100, rnn_units=64, dense_size=64, dropout_rate=0.3, max_seq_length=100):\n",
    "    rnn_model = Sequential([\n",
    "        Embedding(num_words, embedding_dim, input_length=max_seq_length),\n",
    "        SimpleRNN(units=rnn_units, return_sequences=False),\n",
    "        Dense(dense_size, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(4, activation='softmax')\n",
    "    ])\n",
    "    rnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return rnn_model\n",
    "\n",
    "# Define a callback to save the model with the best validation accuracy\n",
    "best_model = ModelCheckpoint('best_model.h5', save_best_only=True, save_weights_only=False, monitor='val_accuracy', mode='max')\n",
    "rnn_model = create_rnn()\n",
    "y_train_resampled = pd.Categorical(y_train_resampled)\n",
    "y_train_resampled = y_train_resampled.codes\n",
    "y_train_resampled_cat = pd.get_dummies(y_train_resampled).values\n",
    "y_test = pd.Categorical(y_test)\n",
    "y_test = y_test.codes\n",
    "y_test_cat = pd.get_dummies(y_test).values\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "filepath='best_model.h5',\n",
    "monitor='val_loss',\n",
    "save_best_only=True,\n",
    "save_weights_only=False,\n",
    "mode='auto',\n",
    "save_freq='epoch'\n",
    ")\n",
    "\n",
    "rnn_history = rnn_model.fit(X_train_resampled, y_train_resampled_cat,\n",
    "epochs=10,\n",
    "batch_size=32,\n",
    "validation_data=(X_test_seq_padded, y_test_cat),\n",
    "callbacks=[checkpoint_callback])\n",
    "\n",
    "#Load the best model\n",
    "rnn_model.load_weights('best_model.h5')\n",
    "\n",
    "#Evaluate the model on the test set\n",
    "y_pred = rnn_model.predict(X_test_seq_padded)\n",
    "y_pred_class = y_pred.argmax(axis=-1)\n",
    "print(classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a74e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('final_project_cleaned.csv')\n",
    "\n",
    "# Preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # Join tokens back into text\n",
    "    text = ' '.join(tokens)\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the text data and pad the sequences to a fixed length\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_seq_padded = pad_sequences(X_train_seq, maxlen=100)\n",
    "\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_seq_padded = pad_sequences(X_test_seq, maxlen=100)\n",
    "\n",
    "# Use RandomOversampling to oversample the minority classes in the training data\n",
    "ros = RandomOverSampler()\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_seq_padded, y_train)\n",
    "def create_rnn(num_words=20000, embedding_dim=100, rnn_units=64, dense_size=64, dropout_rate=0.3, max_seq_length=100):\n",
    "    rnn_model = Sequential([\n",
    "        Embedding(num_words, embedding_dim, input_length=max_seq_length),\n",
    "        SimpleRNN(units=rnn_units, return_sequences=False),\n",
    "        Dense(dense_size, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(4, activation='softmax')\n",
    "    ])\n",
    "    rnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return rnn_model\n",
    "\n",
    "# Define a callback to save the model with the best validation accuracy\n",
    "best_model = ModelCheckpoint('best_model.h5', save_best_only=True, save_weights_only=False, monitor='val_accuracy', mode='max')\n",
    "rnn_model = create_rnn()\n",
    "y_train_resampled = pd.Categorical(y_train_resampled)\n",
    "y_train_resampled = y_train_resampled.codes\n",
    "y_train_resampled_cat = pd.get_dummies(y_train_resampled).values\n",
    "y_test = pd.Categorical(y_test)\n",
    "y_test = y_test.codes\n",
    "y_test_cat = pd.get_dummies(y_test).values\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "filepath='best_model.h5',\n",
    "monitor='val_loss',\n",
    "save_best_only=True,\n",
    "save_weights_only=False,\n",
    "mode='auto',\n",
    "save_freq='epoch'\n",
    ")\n",
    "\n",
    "rnn_history = rnn_model.fit(X_train_resampled, y_train_resampled_cat,\n",
    "epochs=10,\n",
    "batch_size=32,\n",
    "validation_data=(X_test_seq_padded, y_test_cat),\n",
    "callbacks=[checkpoint_callback])\n",
    "\n",
    "#Load the best model\n",
    "rnn_model.load_weights('best_model.h5')\n",
    "\n",
    "#Evaluate the model on the test set\n",
    "y_pred = rnn_model.predict(X_test_seq_padded)\n",
    "y_pred_class = y_pred.argmax(axis=-1)\n",
    "print(classification_report(y_test, y_pred_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
